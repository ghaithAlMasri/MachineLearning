{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ghaith AlMasri"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1\n",
    "Wahrscheinlichkeit (in %) für eine unbrauchbare Ware:\n",
    "Probability of machine A producing unusable goods = Frequency of machine A usage * Scrap rate of machine A = 0.5 * 0.05 = 0.025\n",
    "\n",
    "Probability of machine B producing unusable goods = Frequency of machine B usage * Scrap rate of machine B = 0.3 * 0.1 = 0.03\n",
    "\n",
    "Probability of machine C producing unusable goods = Frequency of machine C usage * Scrap rate of machine C = 0.2 * 0.15 = 0.03\n",
    "\n",
    "Now, we can sum up these probabilities:\n",
    "\n",
    "Probability of unusable goods = 0.025 + 0.03 + 0.03 = 0.085\n",
    "\n",
    "Therefore, the probability of unusable goods is 0.085 or 8.5%.\n",
    "\n",
    "\n",
    "\n",
    "Q2\n",
    "Bayes' Theorem: It calculates the probability of an event based on prior knowledge. Mathematically: P(A|B) = (P(B|A) * P(A)) / P(B). It's significant for learning systems as it enables updating beliefs with new evidence.\n",
    "\n",
    "Mistakes Regarding Bayes' Theorem: Common mistakes include misinterpreting conditional probabilities, neglecting prior probabilities, and assuming independence between events.\n",
    "\n",
    "\"Naive\" in Naive Bayes Classifier: It assumes independence between features, which is often unrealistic but simplifies the model. Despite this assumption, Naive Bayes classifiers are effective in many applications.\n",
    "\n",
    "Filtering SPAMs using NB: Naive Bayes classifiers are used for spam filtering due to their simplicity. They classify emails based on the occurrence of specific words or features. While effective, they may not catch all types of spam and are often combined with other techniques for better filtering.\n",
    "\n",
    "\n",
    "Q4\n",
    "P(A|B₁) = (P(B₁|A) * P(A)) / (P(B₁|A) * P(A) + P(B₁|B) * P(B) + P(B₁|C) * P(C))\n",
    "= (0.1 * 1/3) / (0.1 * 1/3 + 0.5 * 1/3 + 0.8 * 1/3)\n",
    "= 0.0625\n",
    "\n",
    "P(B|B₁) = (P(B₁|B) * P(B)) / (P(B₁|A) * P(A) + P(B₁|B) * P(B) + P(B₁|C) * P(C))\n",
    "= (0.5 * 1/3) / (0.1 * 1/3 + 0.5 * 1/3 + 0.8 * 1/3)\n",
    "= 0.3125\n",
    "\n",
    "P(C|B₁) = (P(B₁|C) * P(C)) / (P(B₁|A) * P(A) + P(B₁|B) * P(B) + P(B₁|C) * P(C))\n",
    "= (0.8 * 1/3) / (0.1 * 1/3 + 0.5 * 1/3 + 0.8 * 1/3)\n",
    "= 0.625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier Scores:\n",
      "Accuracy: 0.8472222222222222\n",
      "Precision: 0.8750603074057791\n",
      "Recall: 0.8472222222222222\n",
      "F1 Score: 0.8489770318561581\n",
      "\n",
      "K-Nearest Neighbors (KNN) Scores:\n",
      "Accuracy: 0.9861111111111112\n",
      "Precision: 0.9861869867863546\n",
      "Recall: 0.9861111111111112\n",
      "F1 Score: 0.9860800746632832\n",
      "\n",
      "Decision Tree Classifier Scores:\n",
      "Accuracy: 0.8611111111111112\n",
      "Precision: 0.8669305600958919\n",
      "Recall: 0.8611111111111112\n",
      "F1 Score: 0.8603882431886405\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "iris = load_digits()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_y_pred = nb_model.predict(X_test)\n",
    "# print(nb_y_pred, y_test)\n",
    "\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_y_pred = knn_model.predict(X_test)\n",
    "# print(knn_y_pred, y_test)\n",
    "\n",
    "\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_y_pred = dt_model.predict(X_test)\n",
    "# print(dt_y_pred, y_test)\n",
    "\n",
    "\n",
    "\n",
    "nb_accuracy = accuracy_score(y_test, nb_y_pred)\n",
    "knn_accuracy = accuracy_score(y_test, knn_y_pred)\n",
    "dt_accuracy = accuracy_score(y_test, dt_y_pred)\n",
    "\n",
    "nb_precision = precision_score(y_test, nb_y_pred, average='weighted')\n",
    "knn_precision = precision_score(y_test, knn_y_pred, average='weighted')\n",
    "dt_precision = precision_score(y_test, dt_y_pred, average='weighted')\n",
    "\n",
    "nb_recall = recall_score(y_test, nb_y_pred, average='weighted')\n",
    "knn_recall = recall_score(y_test, knn_y_pred, average='weighted')\n",
    "dt_recall = recall_score(y_test, dt_y_pred, average='weighted')\n",
    "\n",
    "nb_f1 = f1_score(y_test, nb_y_pred, average='weighted')\n",
    "knn_f1 = f1_score(y_test, knn_y_pred, average='weighted')\n",
    "dt_f1 = f1_score(y_test, dt_y_pred, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Naive Bayes Classifier Scores:\")\n",
    "print(\"Accuracy:\", nb_accuracy)\n",
    "print(\"Precision:\", nb_precision)\n",
    "print(\"Recall:\", nb_recall)\n",
    "print(\"F1 Score:\", nb_f1)\n",
    "print(\"\")\n",
    "\n",
    "print(\"K-Nearest Neighbors (KNN) Scores:\")\n",
    "print(\"Accuracy:\", knn_accuracy)\n",
    "print(\"Precision:\", knn_precision)\n",
    "print(\"Recall:\", knn_recall)\n",
    "print(\"F1 Score:\", knn_f1)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Decision Tree Classifier Scores:\")\n",
    "print(\"Accuracy:\", dt_accuracy)\n",
    "print(\"Precision:\", dt_precision)\n",
    "print(\"Recall:\", dt_recall)\n",
    "print(\"F1 Score:\", dt_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
